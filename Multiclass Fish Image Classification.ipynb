{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc076bae-a142-4aa3-b1b1-6871d2119ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c84c61a-5b44-4dbf-8a46-ad29159ac047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed.\n",
      "path_to_extract_directory\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('Dataset.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('path_to_extract_directory')\n",
    "    print('Extraction completed.')\n",
    "    new_data_dir = 'path_to_extract_directory'\n",
    "    print(new_data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9681a181-d97d-42ac-878a-dcb47e68d612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6225 images belonging to 11 classes.\n",
      "Found 1092 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing and Augmentation\n",
    "# Define dataset directory\n",
    "new_data_dir = 'path_to_extract_directory/images.cv_jzk6llhf18tm3k0kyttxz/data'  # TODO: Update with your dataset directory\n",
    "\n",
    "# Data Preprocessing\n",
    "img_height, img_width = 224, 224  # Example for VGG16, change if needed\n",
    "batch_size = 32\n",
    "\n",
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(new_data_dir, 'train'),\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    os.path.join(new_data_dir, 'val'),\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96a090d7-df1f-4675-be4c-868a152297f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as t\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28129237-dab9-4f1b-bb92-f91705e89249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\midun\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.4830 - loss: 1.9105"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1435s\u001b[0m 7s/step - accuracy: 0.4839 - loss: 1.9068 - val_accuracy: 0.8636 - val_loss: 0.4942\n",
      "Epoch 2/30\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8184 - loss: 0.5607"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1563s\u001b[0m 8s/step - accuracy: 0.8185 - loss: 0.5602 - val_accuracy: 0.9332 - val_loss: 0.2567\n",
      "Epoch 3/30\n",
      "\u001b[1m 82/195\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m7:58\u001b[0m 4s/step - accuracy: 0.8814 - loss: 0.3549"
     ]
    }
   ],
   "source": [
    "# Function to create a transferred model\n",
    "def create_transfer_model(base_model):\n",
    "    model = models.Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(len(train_generator.class_indices), activation='softmax'))\n",
    "\n",
    "    base_model.trainable = False  # Freeze the base model\n",
    "\n",
    "    return model\n",
    "\n",
    "# Load a pre-trained model\n",
    "base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "transfer_learning_model = create_transfer_model(base_model)\n",
    "\n",
    "transfer_learning_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath='best_model.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "# Train transfer learning model\n",
    "transfer_history = transfer_learning_model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=30,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8ad873-c15b-4a5d-866e-a76c9732929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the CNN Model\n",
    "train_generator.reset()  # Reset generator for evaluation\n",
    "cnn_eval = cnn_model.evaluate(validation_generator)\n",
    "print('CNN Model Evaluation:', cnn_eval)\n",
    "\n",
    "# Evaluate transfer learning model\n",
    "transfer_learning_model.evaluate(validation_generator)\n",
    "\n",
    "# Confusion Matrix and Classification Report\n",
    "val_steps = validation_generator.samples // batch_size\n",
    "predictions = cnn_model.predict(validation_generator, steps=val_steps)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = validation_generator.classes\n",
    "class_labels = list(validation_generator.class_indices.keys())\n",
    "\n",
    "print(classification_report(true_classes, predicted_classes, target_names=class_labels))\n",
    "\n",
    "# Confusion Matrix Plot\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(cm, interpolation='nearest')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(class_labels))\n",
    "plt.xticks(tick_marks, class_labels, rotation=45)\n",
    "plt.yticks(tick_marks, class_labels)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde30d71-8024-4331-ab9b-d3fada31900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model for future predictions\n",
    "transfer_learning_model.save('best_transfer_learning_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940ef8b9-0b1c-41d8-bab7-e80904540918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Streamlit app for deployment\n",
    "st.title('Fish Classification App')\n",
    "st.write(\"Upload a fish image to classify\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Choose an image...\", type=\"jpg\")\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    # Load and preprocess the image\n",
    "    img = tf.keras.preprocessing.image.load_img(uploaded_file, target_size=(img_height, img_width))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Perform prediction\n",
    "    predictions = transfer_learning_model.predict(img_array)\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "    predicted_label = class_labels[predicted_class[0]]\n",
    "\n",
    "    st.image(img, caption='Uploaded Image', use_column_width=True)\n",
    "    st.write(f\"Predicted Label: {predicted_label}\")\n",
    "    st.write(f\"Confidence Score: {np.max(predictions) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb61f0f1-547e-4c49-995e-1b94718a0d11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12a3460-0cfa-4354-9076-be325d20c57b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
